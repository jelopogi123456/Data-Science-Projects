{"cells":[{"source":"# Analyzing River Thames Water Levels\nTime series data is everywhere, from watching your stock portfolio to monitoring climate change, and even live-tracking as local cases of a virus become a global pandemic. In this project, you’ll work with a time series that tracks the tide levels of the Thames River. You’ll first load the data and inspect it data visually, and then perform calculations on the dataset to generate some summary statistics. You’ll end by decomposing the time series into its component attributes and analyzing them. \n\nThe original dataset is available from the British Oceanographic Data Center [here](https://www.bodc.ac.uk/data/published_data_library/catalogue/10.5285/b66afb2c-cd53-7de9-e053-6c86abc0d251) and you can read all about this fascinating archival story in [this article](https://www.nature.com/articles/s41597-022-01223-7) from the Nature journal.\n\nHere's a map of the locations of the tidal gauges along the River Thames in London.\n\n![](locations.png)\n\nThe dataset comes with a file called `Data_description.pdf`. The dataset consists of 13 `.txt` files, containing comma separated data. We'll begin by analyzing one of them, the London Bridge gauge, and preparing it for analysis. The same code can be used to analyze data from other files (i.e. other gauges along the river) later.\n\n\n\n| Variable Name | Description | Format |\n| ------------- | ----------- | ------ |\n| Date and time | Date and time of measurement to GMT. Note the tide gauge is accurate to one minute. | dd/mm/yyyy hh:mm:ss |\n| Water level | High or low water level measured by tide gauge. Tide gauges are accurate to 1 centimetre. | metres (Admiralty Chart Datum (CD), Ordnance Datum Newlyn (ODN or Trinity High Water (THW)) | \n| Flag | High water flag = 1, low water flag = 0 | Categorical (0 or 1) |","metadata":{"tags":[]},"id":"35d4e17b-eeb6-40dd-a140-7b949390e115","cell_type":"markdown","attachments":{}},{"source":"# Package imports\nimport pandas as pd                \nfrom scipy.stats import iqr\n\ndef IQR(column): \n    q25, q75 = column.quantile([0.25, 0.75])\n    return q75-q25\n\n# Load the data from London Bridge\nlb = pd.read_csv('data/10-11_London_Bridge.txt') # Comma-separated .txt file\n\n# Take only the first three columns\ndf = lb.iloc[:, :3]\n\n# Rename columns\ndf.columns = ['datetime', 'water_level', 'is_high_tide']\n\n# Convert to datetime\ndf['datetime'] = pd.to_datetime(df['datetime'])\n\n# Convert to float\ndf['water_level'] = df.water_level.astype(float)\n\n# Create extra month and year columns for easy access\ndf['month'] = df['datetime'].dt.month\ndf['year'] = df['datetime'].dt.year\n\n# Filter df for high and low tide\ntide_high = df.query('is_high_tide==1')['water_level']\ntide_low = df.query('is_high_tide==0')['water_level']\n\n# Create summary statistics\nhigh_statistics = tide_high.agg({'mean', 'median', IQR})\nlow_statistics = tide_low.agg({'mean', 'median', IQR})\n\n# Calculate ratio of high tide days\nall_high_days = df.query('is_high_tide==1').groupby('year').count()['water_level']\nhigh_days = df.query(f'(water_level>{tide_high.quantile(.75)}) & (is_high_tide==1)').groupby('year').count()['water_level']\nhigh_ratio = (high_days/all_high_days).reset_index()\n\n# Calculate ratio of low tide days\nall_low_days = df.query('is_high_tide==0').groupby('year').count()['water_level']\nlow_days = df.query(f'(water_level<{tide_low.quantile(.25)}) & (is_high_tide==0)').groupby('year').count()['water_level']\nlow_ratio = (low_days/all_low_days).reset_index()\n\nsolution = {'high_statistics': high_statistics, 'low_statistics': low_statistics, 'high_ratio': high_ratio, 'low_ratio':low_ratio}\nprint(solution)\n\n","metadata":{"executionTime":8482,"lastSuccessfullyExecutedCode":"# Package imports\nimport pandas as pd                \nfrom scipy.stats import iqr\n\ndef IQR(column): \n    q25, q75 = column.quantile([0.25, 0.75])\n    return q75-q25\n\n# Load the data from London Bridge\nlb = pd.read_csv('data/10-11_London_Bridge.txt') # Comma-separated .txt file\n\n# Take only the first three columns\ndf = lb.iloc[:, :3]\n\n# Rename columns\ndf.columns = ['datetime', 'water_level', 'is_high_tide']\n\n# Convert to datetime\ndf['datetime'] = pd.to_datetime(df['datetime'])\n\n# Convert to float\ndf['water_level'] = df.water_level.astype(float)\n\n# Create extra month and year columns for easy access\ndf['month'] = df['datetime'].dt.month\ndf['year'] = df['datetime'].dt.year\n\n# Filter df for high and low tide\ntide_high = df.query('is_high_tide==1')['water_level']\ntide_low = df.query('is_high_tide==0')['water_level']\n\n# Create summary statistics\nhigh_statistics = tide_high.agg({'mean', 'median', IQR})\nlow_statistics = tide_low.agg({'mean', 'median', IQR})\n\n# Calculate ratio of high tide days\nall_high_days = df.query('is_high_tide==1').groupby('year').count()['water_level']\nhigh_days = df.query(f'(water_level>{tide_high.quantile(.75)}) & (is_high_tide==1)').groupby('year').count()['water_level']\nhigh_ratio = (high_days/all_high_days).reset_index()\n\n# Calculate ratio of low tide days\nall_low_days = df.query('is_high_tide==0').groupby('year').count()['water_level']\nlow_days = df.query(f'(water_level<{tide_low.quantile(.25)}) & (is_high_tide==0)').groupby('year').count()['water_level']\nlow_ratio = (low_days/all_low_days).reset_index()\n\nsolution = {'high_statistics': high_statistics, 'low_statistics': low_statistics, 'high_ratio': high_ratio, 'low_ratio':low_ratio}\nprint(solution)\n\n"},"id":"2ca4359b-3fb7-4cfc-8017-36f70e928fba","cell_type":"code","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"{'high_statistics': IQR       0.743600\nmean      3.318373\nmedian    3.352600\nName: water_level, dtype: float64, 'low_statistics': IQR       0.538200\nmean     -2.383737\nmedian   -2.412900\nName: water_level, dtype: float64, 'high_ratio':     year  water_level\n0   1911     0.032787\n1   1912     0.127469\n2   1913     0.186846\n3   1914     0.161572\n4   1915     0.219219\n..   ...          ...\n80  1991     0.252125\n81  1992     0.265912\n82  1993     0.317597\n83  1994     0.357447\n84  1995     0.324823\n\n[85 rows x 2 columns], 'low_ratio':     year  water_level\n0   1911     0.203463\n1   1912     0.192793\n2   1913     0.102985\n3   1914     0.141618\n4   1915     0.139818\n..   ...          ...\n80  1991     0.312057\n81  1992     0.265912\n82  1993     0.252496\n83  1994     0.252482\n84  1995     0.246809\n\n[85 rows x 2 columns]}\n"}]}],"metadata":{"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}